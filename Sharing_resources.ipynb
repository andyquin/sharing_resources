{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### functions to transform 1-array into triangular inf matrix  and vice versa ####\n",
    "\n",
    "def i2j_to_k(i, j):\n",
    "    return i*(i-1)/2 + j\n",
    "\n",
    "def k_to_i2j(k):\n",
    "    i = int((1+math.sqrt(1+8*k))/2)\n",
    "    j = int(k - i*(i-1)/2)\n",
    "    return (i,j)\n",
    "    \n",
    "\n",
    "def d1_2_mat(d):\n",
    "    l = len(d)\n",
    "    (n, _) = k_to_i2j(l)\n",
    "    #print(n)\n",
    "    mat = np.zeros([n,n])\n",
    "    for k in range(l):\n",
    "            (i,j) = k_to_i2j(k)\n",
    "            mat[i,j] = d[k]\n",
    "            mat[j,i] = -d[k]\n",
    "    return mat\n",
    "\n",
    "def mat_2_d1(mat):\n",
    "    \n",
    "    (n,_) = np.shape(mat)\n",
    "    n-=1\n",
    "    k_max = int(n*(n-1)/2 + n)\n",
    "    liste = []\n",
    "    for k in range(k_max):\n",
    "        (i,j) = k_to_i2j(k)\n",
    "        liste.append(mat[k_to_i2j(k)])\n",
    "        \n",
    "    return np.array(liste)\n",
    "\n",
    "\n",
    "\n",
    "def d1_2_mat_list(d, n_Item):\n",
    "    \n",
    "    item_list = np.reshape(np.array(d), (n_Item, -1))\n",
    "    l = len(item_list[0])\n",
    "    \n",
    "    (n, _) = k_to_i2j(l)\n",
    "\n",
    "    mat = np.zeros([n_Item,n,n])\n",
    "    \n",
    "    for it in range(n_Item):\n",
    "\n",
    "        for k in range(l):\n",
    "                (i,j) = k_to_i2j(k)\n",
    "                mat[it,i,j] = item_list[it,k]\n",
    "                mat[it,j,i] = -item_list[it,k]\n",
    "    return mat\n",
    "\n",
    "def mat_2_d1_list(mat):\n",
    "    \n",
    "    liste_totale = []\n",
    "    (n_item, n,_) = np.shape(mat)\n",
    "    n-=1\n",
    "    k_max = int(n*(n-1)/2 + n)\n",
    "    for it in range(n_item):\n",
    "        liste = []\n",
    "        for k in range(k_max):\n",
    "            (i,j) = k_to_i2j(k)\n",
    "            liste.append(mat[it,i,j])\n",
    "            \n",
    "        liste_totale+= liste\n",
    "\n",
    "    return np.array(liste_totale)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_cooperation_A(env, id_agent_source, last_offer): #ratio other agent gave / what I could give\n",
    "    n_agents = env.n_agents\n",
    "    agent = env.agents[id_agent_source]\n",
    "    history = env.transactions_history_numpy\n",
    "    if len(history) < 2:\n",
    "        return np.zeros(n_agents)\n",
    "    else:\n",
    "        #print(history[-2])\n",
    "        last_trans = history[-2].sum(1) #what each agent gave\n",
    "        #last_offer = agent.last_offers[-1]\n",
    "        my_offer_max = np.sum(np.maximum(last_offer,0))\n",
    "        \n",
    "        #print(\"last_trans\", last_trans)\n",
    "        \n",
    "        coop_degrees = np.clip(last_trans/my_offer_max,0,1)\n",
    "    \n",
    "        return coop_degrees\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_cooperation_B(env, id_agent_source, last_offer): #ratio other agent gave ME * (N_agent-1) / what I could give\n",
    "    n_agents = env.n_agents\n",
    "    agent = env.agents[id_agent_source]\n",
    "    history = env.transactions_history_numpy\n",
    "    if len(history) < 2:\n",
    "        return np.zeros(n_agents)\n",
    "    else:\n",
    "        #print(history[-2])\n",
    "        last_trans = history[-2][:,id_agent_source]*(n_agents-1) #what each agent gave\n",
    "        #last_offer = agent.last_offers[-1]\n",
    "        my_offer_max = np.sum(np.maximum(last_offer,0))\n",
    "        \n",
    "        #print(\"last_trans\", last_trans)\n",
    "        \n",
    "        coop_degrees = np.clip(last_trans/my_offer_max,0,1)\n",
    "    \n",
    "        return coop_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFT(alpha, r, beta=0):\n",
    "    def function(old_coop_degrees, detected_coop_degrees, r):\n",
    "        delta = detected_coop_degrees - old_coop_degrees\n",
    "        r = np.maximum(r + beta*delta,0)\n",
    "        output = alpha*old_coop_degrees + (1-alpha)*(r + (1-r)*detected_coop_degrees)        \n",
    "        return output, r\n",
    "        \n",
    "    return function, r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2 = TFT(0.1,0.2,0.7)\n",
    "algo1 = TFT(0.2,0.1,0.6)\n",
    "egoist = TFT(1,0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, id_agent, n_agents, n_items, neg_algo=0):\n",
    "        self.n_agents = n_agents\n",
    "        self.n_items = n_items\n",
    "        self.id_agent = id_agent\n",
    "        self.old_coop_degrees = np.zeros(self.n_agents)\n",
    "        self.ut_function = []\n",
    "        self.last_offers = []\n",
    "        tft_algo, r = neg_algo\n",
    "        self.negociation_algo =  tft_algo\n",
    "        self.r = r*np.ones(self.n_agents)\n",
    "        \n",
    "    def coop_detection(self, env):\n",
    "        n_agents = env.n_agents\n",
    "        id_agent_source = self.id_agent\n",
    "        if len(self.last_offers) == 0:\n",
    "            return np.zeros(n_agents)\n",
    "            #print(\"non last offers\")\n",
    "        else:\n",
    "            #print(\"presence last offers\")\n",
    "            last_offer = self.last_offers[-1]\n",
    "            output = detection_cooperation_B(env, id_agent_source, last_offer)\n",
    "            return output \n",
    "        \n",
    "    def offer(self, env):\n",
    "        tran= env.optimize_localy(self.id_agent)\n",
    "        self.last_offers.append(tran)\n",
    "        return tran\n",
    "    \n",
    "    def negociation(self, detected_coop_degrees):\n",
    "        output, r_new = self.negociation_algo(self.old_coop_degrees, detected_coop_degrees, self.r)\n",
    "        self.r = r_new\n",
    "        self.old_coop_degrees = output\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo2 = TFT(0.1,0.2,0.7)\n",
    "algo1 = TFT(0.2,0.1,0.6)\n",
    "egoist = TFT(1,0,0.5)\n",
    "\n",
    "n_A = 3\n",
    "n_I = 3\n",
    "a1 = Agent(0, n_A, n_I, algo1)\n",
    "a2 = Agent(1, n_A, n_I, algo1)\n",
    "a3 = Agent(2, n_A, n_I, algo1)\n",
    "#a4 = Agent(3, n_A, n_I, algo1)\n",
    "\n",
    "liste_agents_A = [a1, a2, a3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, n_agents, n_items, list_agents = []):\n",
    "        self.n_agents = n_agents\n",
    "        self.agents = list_agents\n",
    "        self.n_items = n_items\n",
    "        self.t = 0 #step \n",
    "        self.state = np.zeros([n_agents, n_items])\n",
    "        self.states_history = [] #history of states\n",
    "        self.transactions_history = []\n",
    "        self.transactions_history_numpy = []\n",
    "        \n",
    "        self.optimal_SW = 0 #optimal social welfare \n",
    "        self.hist_SW = [] #evolution of social welfare\n",
    "        self.hist_ut_agents = [[] for _ in range(self.n_agents)] #evolution of utilities of agents \n",
    "        \n",
    "        self.hist_coop_degrees = [] #evolution of cooperation degrees\n",
    "        \n",
    "        \n",
    "    def init_state(self, state):\n",
    "        s = np.copy(state)\n",
    "        self.state = s\n",
    "        self.t = 0\n",
    "        \n",
    "    def next_round(self):\n",
    "        self.t += 1\n",
    "        self.transactions_history.append([])\n",
    "        self.transactions_history_numpy.append(np.zeros([env.n_agents, env.n_agents]))\n",
    "        \n",
    "    def replace_agents(self, list_agents):\n",
    "        self.agents = list_agents\n",
    "        \n",
    "    def clip_state(self, lb, ub):\n",
    "        self.state = np.clip(self.state, lb, ub)\n",
    "    \n",
    "    def random_init(self, mean=0, std=1):\n",
    "        self.state = np.random.normal(mean, std, size = [self.n_agents, self.n_items])\n",
    "        \n",
    "    def transaction(self, id_agent_source, id_agent_target, id_item, quantity):\n",
    "        self.state[id_agent_target, id_item] += quantity\n",
    "        self.state[id_agent_source, id_item] -= quantity\n",
    "        \n",
    "        self.transactions_history[-1].append((env.t, id_agent_source, id_agent_target, id_item, quantity))\n",
    "        \n",
    "        #update quantities shared between agents (independently of items)\n",
    "        self.transactions_history_numpy[-1][id_agent_source, id_agent_target] += quantity\n",
    "        \n",
    "        \n",
    "        \n",
    "    def add_transactions_np(self, state, transactions):\n",
    "        #state : array nA x nI\n",
    "        #transactions : array nI x nA x nA\n",
    "\n",
    "        (nA, nI) = np.shape(state)\n",
    "        new_s = state.copy()\n",
    "        for item in range(nI):\n",
    "            for agent in range(nA):\n",
    "                new_s[agent, item] -= transactions[item, agent, : ].sum()\n",
    "\n",
    "        return new_s\n",
    "    \n",
    "    def add_transactions_var(self, state, trans_var):\n",
    "        #state : array nA x nI\n",
    "        #trans_var : variable for optimisation, liste\n",
    "        transactions = d1_2_mat_list(trans_var, self.n_items)\n",
    "        return self.add_transactions_np(state, transactions)\n",
    "    \n",
    "\n",
    "    def global_utility(self, state, lb =-2.0, ub = 100.0):\n",
    "        s = np.copy(state)\n",
    "        s = np.clip(s, lb, ub)\n",
    "        return -np.log(s+2+1e-8).sum()\n",
    "    \n",
    "    def local_utility(self, state, id_agent):\n",
    "        s = np.copy(state)\n",
    "        s = s[id_agent,:]\n",
    "        s = np.clip(s, -2, 100)\n",
    "        return -np.log(s+2+1e-8).sum()\n",
    "    \n",
    "    def optimize_localy(self, id_agent, lb = -4, ub = 4, min_cons = -1):\n",
    "        (nA, nI) = self.n_agents, self.n_items\n",
    "        size_var = nI #size of variable \n",
    "        lb_list = lb*np.ones(size_var) #lower bounds\n",
    "        ub_list = ub*np.ones(size_var) #upper bounds\n",
    "        \n",
    "        s_tmp = np.copy(self.state)\n",
    "        \n",
    "        def f_opt(dx): #utility function for pso\n",
    "            s = np.copy(s_tmp)\n",
    "            s[id_agent, :] += dx\n",
    "            return self.local_utility(s, id_agent) + 0.01 * np.linalg.norm(dx)\n",
    "            \n",
    "        def constraint(dx):\n",
    "            s = np.copy(s_tmp)\n",
    "            s[id_agent, :] += dx       \n",
    "            s = s[id_agent]        \n",
    "            const_out1 = s-min_cons\n",
    "            const_out2 = np.array([-dx.sum()])\n",
    "            const_out = np.concatenate((const_out1,const_out2))\n",
    "\n",
    "            return const_out\n",
    "        \n",
    "        xopt, fopt = pso(f_opt, f_ieqcons= constraint, lb=lb_list, ub=ub_list, maxiter=200, swarmsize=200)\n",
    "        \n",
    "        return(xopt)\n",
    "    \n",
    "    \n",
    "    def optimize_globably(self, lb = -2.0, ub = 2.0):\n",
    "        (nA, nI) = self.n_agents, self.n_items\n",
    "        k_max = nI * ( int((nA-1)*(nA-2)/2 + nA-1)  )\n",
    "        d_var = np.zeros(k_max)\n",
    "        lb_list = lb*np.ones(k_max)\n",
    "        ub_list = ub*np.ones(k_max)\n",
    "        \n",
    "        s = self.state.copy()\n",
    "        \n",
    "        def f_opt(dx):\n",
    "            \n",
    "            trans_var_np = d1_2_mat_list(dx, self.n_items)\n",
    "            new_s_tmp = self.add_transactions_np(s, trans_var_np)\n",
    "            \n",
    "            fusion_items = trans_var_np.sum(0)\n",
    "            received_agents = fusion_items.sum(1)\n",
    "            \n",
    "            return self.global_utility(new_s_tmp) + 0.1*np.linalg.norm(received_agents) + 0.1 * np.linalg.norm(dx) \n",
    "    \n",
    "        def constraint(dx):\n",
    "            \n",
    "            trans_var_np = d1_2_mat_list(dx, self.n_items)\n",
    "            new_s_tmp = self.add_transactions_np(s, trans_var_np)\n",
    "            \n",
    "            const_out = new_s_tmp - min_cons\n",
    "            #const_out2 = np.array([-dx.sum()])\n",
    "            #const_out = np.concatenate((const_out1,const_out2))\n",
    "\n",
    "            return const_out\n",
    "    \n",
    "    \n",
    "        xopt, fopt = pso(f_opt, lb_list, ub_list, maxiter=300, swarmsize=300)\n",
    "        \n",
    "        transactions = d1_2_mat_list(xopt, self.n_items)\n",
    "        new_s = self.add_transactions_np(s, transactions)\n",
    "        #print(new_s)\n",
    "        \n",
    "        return(transactions, new_s, env.global_utility(new_s))\n",
    "        \n",
    "    def optimal_social_welfare(self):\n",
    "        (transactions, new_s, fopt) = self.optimize_globably()\n",
    "        self.optimal_SW = fopt\n",
    "        return fopt\n",
    "        \n",
    "    def get_observation(self, id_agent):\n",
    "        return self.state[id_agent, :]\n",
    "    \n",
    "    \n",
    "    def allocation(self, coop_degrees, demands):\n",
    "        \n",
    "        demands_agents = np.maximum(demands,0)\n",
    "        offers_agents = -np.minimum(demands,0)\n",
    "        \n",
    "        for it in range(self.n_items):\n",
    "            for agent_source in range(self.n_agents):\n",
    "                of_source = offers_agents[agent_source, it]\n",
    "                \n",
    "                if of_source > 0: #agent_source can give of_source for item it\n",
    "\n",
    "                    demands_targets = np.zeros([self.n_agents])\n",
    "                    parts_targets = np.zeros([self.n_agents])  \n",
    "                    \n",
    "                    for agent_target in range(self.n_agents):\n",
    "                        dem_target = demands_agents[agent_target, it] #demand of agent_target if < 0\n",
    "                        dem_target_clip = min(dem_target, of_source)\n",
    "                        demands_targets[agent_target] = dem_target_clip\n",
    "                        parts_targets[agent_target] = dem_target_clip\n",
    "                        \n",
    "                    total_demand = demands_targets.sum()\n",
    "\n",
    "                    for agent_target in range(self.n_agents):\n",
    "                        alloc = demands_targets[agent_target]*coop_degrees[agent_source, agent_target]*of_source \n",
    "                        \n",
    "                        if total_demand != 0:\n",
    "                            alloc/= total_demand\n",
    "                        alloc = min(alloc,of_source)\n",
    "                        \n",
    "                        self.transaction(agent_source, agent_target, it, alloc)\n",
    "                    \n",
    "    \n",
    "    def show(self):\n",
    "        fig, axs = plt.subplots(1,self.n_agents)\n",
    "        for i in range(self.n_agents):\n",
    "            axs[i].bar(np.arange(self.n_items),self.get_observation(i), orientation = 'vertical')\n",
    "            axs[i].axis('equal')\n",
    "            axs[i].set_title(\"Agent \"+str(i+1))\n",
    "            axs[i].set_ylim([-1,1])\n",
    "            \n",
    "           \n",
    "    \n",
    "env = Environment(3,4, liste_agents_A)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_B = np.array([\n",
    "    [-1.0,2.0,0.0,1.0],\n",
    "    [3.0,1.0,-1.0,1.0],\n",
    "    [1.0,-1.0,3.0,1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "state_C = np.array([\n",
    "    [0.0,2.0,0.0,1.0,-1.0,1.0],\n",
    "    [2.0,2.0,-1.0,1.0,-1.0,0.0],\n",
    "    [1.0,-1.0,1.0,-1.0,2.0,1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "state_D = np.array([\n",
    "    [-1.0,1.0,0.0,1.0,-1.0,1.0],\n",
    "    [-1.0,1.0,-1.0,1.0,-1.0,0.0],\n",
    "    [1.0,-1.0,1.0,-1.0,1.0,1.0],\n",
    "    [-1.0,0,1.0,-1.0,-1.0,1.0],\n",
    "    \n",
    "])\n",
    "\n",
    "state_E = np.array([[-1.,  2.,  2.],\n",
    "       [ 2.,  2., -1.],\n",
    "       [ 2., -1.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Environment(3,3, liste_agents_A) \n",
    "env.init_state(state_E)\n",
    "\n",
    "#env.init_state(new_s)\n",
    "env.show()\n",
    "#for t in env.history_transaction:\n",
    " #   print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(s, tran_var, lb=-1, ub=10):\n",
    "    ns = np.copy(s)\n",
    "    (nA, nI) = np.shape(ns)\n",
    "    trans_np = d1_2_mat_list(tran_var, nI)\n",
    "    ns = add_transactions(ns, trans_np)\n",
    "    #ns = np.clip(ns, lb, ub)\n",
    "    return np.log(ns+1+1e-8).sum()\n",
    "\n",
    "def constraint(s, tran_var, lb=-1, ub=10):\n",
    "    ns = np.copy(s)\n",
    "    (nA, nI) = np.shape(ns)\n",
    "    trans_np = d1_2_mat_list(tran_var, nI)\n",
    "    ns = add_transactions(ns, trans_np)\n",
    "    #ns = np.clip(ns, lb, ub)\n",
    "    return np.log(ns+1+1e-8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(3,3, liste_agents_A)\n",
    "env.init_state(state_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.init_state(new_s)\n",
    "env.show()\n",
    "print(env.hist_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transa, new_s, opt = env.optimize_globably()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode(env):\n",
    "    n_agents = env.n_agents\n",
    "    n_items = env.n_items\n",
    "    opt_sw = env.optimal_social_welfare()\n",
    "    env.next_round()\n",
    "    \n",
    "    env.states_history.append(env.state)\n",
    "    current_SW = env.global_utility(env.state)\n",
    "    env.hist_SW.append(current_SW)\n",
    "    \n",
    "    for i_A in range(n_agents):\n",
    "        uti_agent = env.local_utility(env.state, i_A)\n",
    "        env.hist_ut_agents[i_A].append(uti_agent)\n",
    "    \n",
    "    env.show()\n",
    "\n",
    "        \n",
    "    \n",
    "    demands = np.zeros([n_agents, n_items])\n",
    "    \n",
    "    \n",
    "    coop_degrees = np.zeros([n_agents, n_agents])\n",
    "    \n",
    "    for i_agent in range(n_agents):\n",
    "        transa = env.agents[i_agent].offer(env)\n",
    "        env.agents[i_agent].last_offers.append(transa)\n",
    "        #print(transa)\n",
    "        \n",
    "        print(\"Agent \",i_agent)\n",
    "        coop_deg_detected = env.agents[i_agent].coop_detection(env)\n",
    "        print(\"coop deg detected \", coop_deg_detected)\n",
    "        \n",
    "        coop_deg_i = env.agents[i_agent].negociation(coop_deg_detected)\n",
    "        print(\"coop deg negociated \", coop_deg_i)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        demands[i_agent, : ] = transa\n",
    "        coop_degrees[i_agent,:] = coop_deg_i\n",
    "        \n",
    "    coop_degrees = np.clip(coop_degrees,0,1)\n",
    "    \n",
    "    print(coop_degrees)\n",
    "    env.hist_coop_degrees.append(coop_degrees)\n",
    "    \n",
    "    \n",
    "    env.allocation(coop_degrees, demands)\n",
    "    #print(np.sum(env.state, axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    episode(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yA = env.hist_ut_agents[0]\n",
    "yB = env.hist_ut_agents[1]\n",
    "yC = env.hist_ut_agents[2]\n",
    "#yD = env.hist_ut_agents[3]\n",
    "y = env.hist_SW\n",
    "\n",
    "yA = [-x for x in yA]\n",
    "yB = [-x for x in yB]\n",
    "yC = [-x for x in yC]\n",
    "#yD = [-x for x in yD]\n",
    "y = [-x for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.hist_SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_coop_degrees(matrix_list):\n",
    "    if matrix_list == []:\n",
    "        return []\n",
    "    else:\n",
    "        (n_A,_) = np.shape(matrix_list[0])\n",
    "        output = [ [[] for _ in range(n_A)], [[] for _ in range(n_A)] ]  #curves for mean receiving AND sending coop degree \n",
    "        for coop_degrees_mat in matrix_list:\n",
    "            rece_coop = coop_degrees_mat.sum(0)\n",
    "            send_coop = coop_degrees_mat.sum(1)\n",
    "            for i_A in range(n_A):\n",
    "                mean_rece = (rece_coop[i_A] - coop_degrees_mat[i_A,i_A])/(n_A-1)\n",
    "                output[0][i_A].append(mean_rece)    #receiving coop degree mean for agent i_A\n",
    "\n",
    "                mean_send = (send_coop[i_A] - coop_degrees_mat[i_A,i_A])/(n_A-1)\n",
    "                output[1][i_A].append(mean_send)    #receiving coop degree mean for agent i_A\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affiche(env, output,lu,uu,lc,uc):\n",
    "    yA = env.hist_ut_agents[0]\n",
    "    yB = env.hist_ut_agents[1]\n",
    "    yC = env.hist_ut_agents[2]\n",
    "    #yD = env.hist_ut_agents[3]\n",
    "    y = env.hist_SW\n",
    "\n",
    "    yA = [-x for x in yA]\n",
    "    yB = [-x for x in yB]\n",
    "    yC = [-x for x in yC]\n",
    "    #yD = [-x for x in yD]\n",
    "    y = [-x for x in y]\n",
    "    \n",
    "    mean_coop_degrees_expe = mean_coop_degrees(env.hist_coop_degrees)\n",
    "    \n",
    "    figure_utilities(y, [yA,yB,yC],'evolution_utilities_'+output+'.svg',10, lu, uu)\n",
    "    \n",
    "    figure_coop_degrees_mean(mean_coop_degrees_expe, 'evolution_cooperation_'+output+'.svg',10, lc, uc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_coop_degrees_expe = mean_coop_degrees(env.hist_coop_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_utilities(sw, list_ut, output_fig, max_t, lu=2,uu=4):\n",
    "    colors = ['b','m','c','r']\n",
    "    t_max = min(len(sw), max_t)\n",
    "    t = np.arange(t_max)\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'b'\n",
    "    ax1.set_xlabel('Rounds', fontsize = 14)\n",
    "    ax1.set_ylabel('Social Welfare', color='g', fontsize = 14)\n",
    "    ax1.plot(t, sw[:t_max], color='g', label=\"Social Welfare\")\n",
    "    ax1.tick_params(axis='y', labelcolor='g', labelsize = 14)\n",
    "    plt.legend(loc=2, fontsize=13)\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('Individual Utility', color=color, fontsize = 14) \n",
    "    ax2.set_ylim(lu, uu)\n",
    "    ax2.tick_params(axis='y', labelcolor=color, labelsize = 14)\n",
    "    ax1.tick_params(axis='x', labelsize = 14)\n",
    "\n",
    "\n",
    "\n",
    "    for i_A in range(len(list_ut)):\n",
    "        color = colors[i_A]\n",
    "        label = \"Agent \"+str(i_A+1)\n",
    "        if i_A == 5:\n",
    "            label = \"Egoist\"\n",
    "        ax2.plot(t, list_ut[i_A][:t_max], color=color, label=label)\n",
    "    \n",
    "    plt.legend(loc=4, fontsize=13)\n",
    "        \n",
    "    fig.tight_layout() # otherwise the right y-label is slightly clipped\n",
    "    fig.savefig(output_fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_utilities(y, [yA,yB,yC],'evolution_utilities_3items-allNices.svg',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_coop_degrees_mean(list_coop, output_fig, max_t, lc=0 ,uc=1):\n",
    "    colors = ['b','m','c','g','r']\n",
    "    \n",
    "    t_max = min(len(list_coop[0][0]), max_t)\n",
    "    t = np.arange(t_max)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'b'\n",
    "    ax1.set_xlabel('Rounds', fontsize=14)\n",
    "    ax1.set_ylabel('Mean Cooperation Degree',fontsize=14)\n",
    "\n",
    "    ax1.set_ylim(lc, uc)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelsize=14)\n",
    "    ax1.tick_params(axis='x', labelsize=14)\n",
    "    \n",
    "\n",
    "\n",
    "    for i_A in range(len(list_coop[0])):\n",
    "        color = colors[i_A]\n",
    "        if i_A != 5:\n",
    "            label = \"Agent \"+str(i_A+1)\n",
    "        else:\n",
    "            label = \"Egoist\"\n",
    "        ax1.plot(t, list_coop[0][i_A][:t_max], color, label = label + \" : receiving\")\n",
    "        ax1.plot(t, list_coop[1][i_A][:t_max], color+\"--\", label = label + \" : sending\")\n",
    "        plt.legend(loc=4,fontsize=13)\n",
    "        \n",
    "    fig.tight_layout() # otherwise the right y-label is slightly clipped\n",
    "    fig.savefig(output_fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_coop_degrees_mean(mean_coop_degrees_expe, \"coop_deg_3items_allNices.svg\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(3,3, liste_agents_A)\n",
    "env.init_state(state_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effiency(list_SW, SWopt):\n",
    "    SW0 = list_SW[0]\n",
    "    output = []\n",
    "    \n",
    "    for sw in list_SW:\n",
    "        e = min((-sw+SW0)/(-SWopt+SW0),1)\n",
    "        output.append(e)\n",
    "        \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def speed(list_eff, T):\n",
    "    final_efficiency = list_eff[-1]\n",
    "    x = np.arange(T)    \n",
    "    return metrics.auc(x, list_eff[:T])/(T*final_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(state, beta, r, alpha, N_iter=10):\n",
    "    algo = TFT(beta,r,alpha)\n",
    "    egoist = TFT(1,0,0.5)\n",
    "\n",
    "    n_A, n_I = np.shape(state)\n",
    "    \n",
    "    T_speed = 10\n",
    "    \n",
    "    T_speed = min(T_speed, N_iter)\n",
    "\n",
    "    \n",
    "    a1 = Agent(0, n_A, n_I, algo)\n",
    "    a2 = Agent(1, n_A, n_I, algo)\n",
    "    a3 = Agent(2, n_A, n_I, algo)\n",
    "\n",
    "    b1 = Agent(0, n_A, n_I, algo)\n",
    "    b2 = Agent(1, n_A, n_I, algo)\n",
    "    b3 = Agent(2, n_A, n_I, egoist)\n",
    "    \n",
    "    c1 = Agent(0, n_A, n_I, algo)\n",
    "    c2 = Agent(1, n_A, n_I, egoist)\n",
    "    c3 = Agent(2, n_A, n_I, egoist)\n",
    "\n",
    "    liste_agents_A = [a1, a2, a3]\n",
    "    liste_agents_B = [b1, b2, b3]\n",
    "    liste_agents_C = [c1, c2, c3]\n",
    "    \n",
    "    envA = Environment(n_A,n_I, liste_agents_A)\n",
    "    envA.init_state(state_E)\n",
    "    \n",
    "    envB = Environment(n_A,n_I, liste_agents_B)\n",
    "    envB.init_state(state_E)\n",
    "    \n",
    "    envC = Environment(n_A,n_I, liste_agents_C)\n",
    "    envC.init_state(state_E)\n",
    "    \n",
    "    tra, ns, swopt = envA.optimize_globably()\n",
    "    \n",
    "    \n",
    "    for i_ep in range(N_iter):\n",
    "        print(\"Env A, episode \", i_ep)\n",
    "        episode(envA)\n",
    "        \n",
    "    for i_ep in range(N_iter):\n",
    "        print(\"Env B, episode \", i_ep)\n",
    "        episode(envB)\n",
    "        \n",
    "    for i_ep in range(N_iter):\n",
    "        print(\"Env C, episode \", i_ep)\n",
    "        episode(envC)\n",
    "        \n",
    "    \n",
    "    effic = effiency(envA.hist_SW, swopt)\n",
    "    \n",
    "    ef = effic[-1]\n",
    "\n",
    "    sp = speed(effic, T_speed)\n",
    "    \n",
    "    ut_max_pers_nices = -1*envA.hist_ut_agents[2][-1] #positive\n",
    "    ut_pers_3egoist = -1*envA.hist_ut_agents[0][0] #positive  \n",
    "    ut_pers_1egoist = -1*envB.hist_ut_agents[2][-1] #positive\n",
    "    ut_pers_2egoist = -1*envC.hist_ut_agents[0][-1] #positive\n",
    "\n",
    "    \n",
    "    print(ut_max_pers_nices, ut_pers_1egoist, ut_pers_2egoist, ut_pers_3egoist)\n",
    "    \n",
    "    ic = (ut_max_pers_nices-ut_pers_1egoist)/ut_max_pers_nices\n",
    "    sf = (ut_pers_2egoist-ut_pers_3egoist)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return [[beta, r, alpha],[envA, envB, envC], ef, sp, ut_max_pers_nices, ut_pers_1egoist, ut_pers_2egoist, ut_pers_3egoist]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "r = 0.1\n",
    "alpha = 0\n",
    "N_iter = 10\n",
    "a = analyse(state_E, beta, r, alpha, N_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envD = a[1][0]\n",
    "envE = a[1][1]\n",
    "envF = a[1][2]\n",
    "\n",
    "\n",
    "ut_max_pers_nices = -1*envD.hist_ut_agents[2][-1] #positive\n",
    "ut_pers_3egoist = -1*envD.hist_ut_agents[0][0] #positive  \n",
    "ut_pers_1egoist = -1*envE.hist_ut_agents[2][-1] #positive\n",
    "ut_pers_2egoist = -1*envF.hist_ut_agents[0][-1] #positive\n",
    "\n",
    "ic = ut_max_pers_nices-ut_pers_1egoist\n",
    "sf = ut_pers_2egoist - ut_pers_3egoist\n",
    "\n",
    "print(ic, sf)\n",
    "\n",
    "print(ut_max_pers_nices, ut_pers_1egoist, ut_pers_2egoist, ut_pers_3egoist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiche(envD,'One_egoist',2,4,-0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_expe(liste_bra):\n",
    "    output = []\n",
    "    for x in liste_bra:\n",
    "        beta, r, alpha = x\n",
    "        N_iter = 15\n",
    "        a = analyse(state_E, beta, r, alpha, N_iter)\n",
    "        output.append(a)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_exp = [(0.1,0.05,0),(0.1,0.02,0)]\n",
    "#liste_exp = [(0.1,0.05,0),(0.1,0.02,0),(0.3,0.1,0),(0.5,0.1,0),(0.7,0.1,0),(0.1,0.1,0.3),(0.1,0.1,0.5),(0.1,0.1,0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = all_expe(liste_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in output:\n",
    "    param,_,e,sp,utN,ut1E,ut2E,ut3E = x\n",
    "    print(param, e, sp, ut1E, ut2E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
